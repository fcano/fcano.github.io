<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Cybersecurity Notes</title><link href="https://fcano.github.io/" rel="alternate"></link><link href="https://fcano.github.io/feeds/all.atom.xml" rel="self"></link><id>https://fcano.github.io/</id><updated>2021-05-24T00:00:00+02:00</updated><entry><title>New important security feature in the Linux kernel: Landlock</title><link href="https://fcano.github.io/new-important-security-feature-in-linux-kernel-landlock.html" rel="alternate"></link><published>2021-05-24T00:00:00+02:00</published><updated>2021-05-24T00:00:00+02:00</updated><author><name>Florencio Cano</name></author><id>tag:fcano.github.io,2021-05-24:/new-important-security-feature-in-linux-kernel-landlock.html</id><summary type="html">&lt;p&gt;Landlock is yet another sandoxing mechanism for Linux, but with important differences. Its goal is to make possible to restrict access rights to different Linux elements (e.g. filesystem access), in a secure and programmatic way, without the need of admin privileges. Because LandLock is a &lt;a href="https://lwn.net/Articles/804906/"&gt;stackable LSM&lt;/a&gt; (Linux Security â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Landlock is yet another sandoxing mechanism for Linux, but with important differences. Its goal is to make possible to restrict access rights to different Linux elements (e.g. filesystem access), in a secure and programmatic way, without the need of admin privileges. Because LandLock is a &lt;a href="https://lwn.net/Articles/804906/"&gt;stackable LSM&lt;/a&gt; (Linux Security Module), it makes it possible to create safe security sandboxes as new security layers, in addition to the existing system-wide access-controls. This kind of sandbox is expected to help mitigate the security impact of bugs or unexpected/malicious behaviors in user space applications. It is important to remark that Landlock empowers any process, included unprivileged ones, to restrict themselves, reducing the potential impact in case of malicious behavior.&lt;/p&gt;
&lt;h2&gt;Linux Security Modules (LSMs)&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.kernel.org/doc/html/v4.15/admin-guide/LSM/index.html"&gt;Linux Security Module&lt;/a&gt; (LSM) is a framework that provides various security checks to be hooked by the kernel. The name may be confusing as they are not loadable kernel modules. They are selectable at build-time via CONFIG_DEFAULT_SECURITY and can be overridden at boot-time via the "security=..." kernel command line argument.&lt;/p&gt;
&lt;p&gt;The primary users of the LSM interface are Mandatory Access Control (MAC) extensions which provide a comprehensive security policy. Examples include &lt;a href="https://www.redhat.com/en/topics/linux/what-is-selinux"&gt;SELinux&lt;/a&gt;, &lt;a href="https://www.kernel.org/doc/html/v4.14/admin-guide/LSM/Smack.html"&gt;Smack&lt;/a&gt;, &lt;a href="https://www.kernel.org/doc/html/v4.15/admin-guide/LSM/tomoyo.html"&gt;Tomoyo&lt;/a&gt;, &lt;a href="https://apparmor.net/"&gt;AppArmor&lt;/a&gt;, and now, &lt;a href="https://landlock.io/"&gt;Landlock&lt;/a&gt;. Most LSMs choose to extend the capabilities system, building their checks on top of the defined capability hooks, but &lt;a href="https://twitter.com/kees_cook/status/1388758944433147905"&gt;that is not the case of Landlock&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here you can find more information about the &lt;a href="https://www.usenix.org/legacy/event/sec02/full_papers/wright/wright_html/index.html"&gt;design of LSM&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Characteristics of Landlock&lt;/h2&gt;
&lt;p&gt;A key feature of Landlock is that it allows unprivileged users to restrict processes that they run and it can be embeded within the applications themselves. It is not an administrator's mechanism like SELinux, but a user feature. &lt;a href="https://www.kernel.org/doc/html/v4.14/admin-guide/LSM/Smack.html"&gt;In SELinux or Smack, setting policies is a privileged operation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;On the other hand, &lt;a href="https://man7.org/linux/man-pages/man2/seccomp.2.html"&gt;Seccomp&lt;/a&gt; can be used to create sanboxes too, but it has some limitations. For example, it does not allow to filter system calls based on the paths of files they try to access, what Landlock do allow. By restricting what a running process can do, a Landlock-based sandbox can reduce the attack surface of the kernel and make the exploitation of vulnerabilities harder in general. In fact, Landlock is inspired by seccomp-bpf, but instead of filtering syscalls and their raw arguments, a Landlock rule can restrict the use of kernel objects like file hierarchies. The first versions of Landlock were based on eBPF, &lt;a href="https://landlock.io"&gt;but it isn't anymore&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Landlock also takes inspiration from other OS sandbox mechanisms: &lt;a href="https://github.com/dionthegod/XNUSandbox"&gt;XNU Sandbox&lt;/a&gt;, &lt;a href="https://wiki.freebsd.org/Capsicum"&gt;FreeBSD Capsicum&lt;/a&gt; or &lt;a href="https://man.openbsd.org/pledge.2"&gt;OpenBSD Pledge/Unveil&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If a sandboxed program try to access anything outside of the given list (defined by a ruleset or many stacked rulesets), the forbidden call returns EPERM error, but &lt;a href="https://lwn.net/Articles/703876/"&gt;the program is not killed&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The question is, if a program is able to restrict its access, what prevents the same program to get again the permissions? LSM hooks are purely restrictive. They can reduce access, &lt;a href="https://lwn.net/Articles/703876/"&gt;but cannot increase it&lt;/a&gt;. So, unless there's a bug on the implementation, an attacker cannot escape from it.&lt;/p&gt;
&lt;p&gt;In its current form it is not possible to restrict some file-related actions accessible through these syscall families: chdir(2), truncate(2), stat(2), flock(2) chmod(2), chown(2) setxattr(2), ioctl(2), fcntl(2). This was intentional to reduce the code to be included in the kernel and to ease its review. &lt;a href="https://lwn.net/Articles/703876/"&gt;Other subsystems are not covered either&lt;/a&gt; (e.g. network).&lt;/p&gt;
&lt;p&gt;Table from &lt;a href="https://landlock.io/talks/2018-07-04_landlock-pts.pdf"&gt;https://landlock.io/talks/2018-07-04_landlock-pts.pdf&lt;/a&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align="center"&gt;Fine-grained control&lt;/th&gt;
&lt;th align="center"&gt;Embedded policy&lt;/th&gt;
&lt;th align="center"&gt;Unprivileged use&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;SELinux&lt;/td&gt;
&lt;td align="center"&gt;X&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;seccomp-bpf&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;X&lt;/td&gt;
&lt;td align="center"&gt;X&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;namespaces&lt;/td&gt;
&lt;td align="center"&gt;&lt;/td&gt;
&lt;td align="center"&gt;X&lt;/td&gt;
&lt;td align="center"&gt;~&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Landlock&lt;/td&gt;
&lt;td align="center"&gt;X&lt;/td&gt;
&lt;td align="center"&gt;X&lt;/td&gt;
&lt;td align="center"&gt;X&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;How can Landlock be used&lt;/h2&gt;
&lt;p&gt;The main threat model may be seen as &lt;a href="https://lore.kernel.org/lkml/f646e1c7-33cf-333f-070c-0a40ad0468cd@digikod.net/"&gt;protecting from vulnerable (i.e. malicious) code&lt;/a&gt;. But because Landlock policies can be defined by application developers, they also define their own threat model.&lt;/p&gt;
&lt;p&gt;For example, if a browser implements Landlock and restricts itself to the files it needs for running, a vulnerability that is exploitable and which allows code execution will have access only to the file hierarchies that are accessible by the Landlock ruleset defined for the browser, but not to all files and binaries accessible by the user that executes the browser process.&lt;/p&gt;
&lt;p&gt;With Landlock, one thing is what other MACs allow the process to access and a different thing is what the Landlock allows the process to access. Remember that LSM are stackable and restrictive so if standard permissions allow the process, capabilities allow the process, SELinux allows the process (or is disabled), but Landlock does not allow the process, the result will be that the process is not allowed to do that.&lt;/p&gt;
&lt;p&gt;The important thing for me is that with SELinux, the administrator needed to apply the rules for the application to work properly. With Landlock, the rules can be embeded in the application. Each application, in an ideal world, will come with its Landlock rulesets.&lt;/p&gt;
&lt;h2&gt;Proof of Concept&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://lore.kernel.org/lkml/20200511192156.1618284-10-mic@digikod.net/"&gt;Example of a sandboxing process&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://landlock.io/linux-doc/landlock-v34/userspace-api/landlock.html"&gt;Here&lt;/a&gt; can be found an example of &lt;a href="https://landlock.io/linux-doc/landlock-v34/userspace-api/landlock.html"&gt;how to apply a landlock rule&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;When will be Landlock available&lt;/h2&gt;
&lt;p&gt;Landlock will be available in Linux 5.13.&lt;/p&gt;</content><category term="Security"></category><category term="linux"></category><category term="kernel"></category><category term="landlock"></category></entry><entry><title>Looking for the root cause of current cybersecurity problems</title><link href="https://fcano.github.io/looking-for-root-cause-current-cybersecurity-problems.html" rel="alternate"></link><published>2021-05-21T00:00:00+02:00</published><updated>2021-05-21T00:00:00+02:00</updated><author><name>Florencio Cano</name></author><id>tag:fcano.github.io,2021-05-21:/looking-for-root-cause-current-cybersecurity-problems.html</id><summary type="html">&lt;p&gt;I love Goldratt books (&lt;a href="https://www.goodreads.com/book/show/113934.The_Goal"&gt;The Goal&lt;/a&gt;, &lt;a href="https://www.goodreads.com/book/show/157385.It_s_Not_Luck?from_search=true&amp;amp;from_srp=true&amp;amp;qid=dQEjWkU3CN&amp;amp;rank=1"&gt;It's Not Luck&lt;/a&gt;, &lt;a href="https://www.goodreads.com/book/show/4845427-the-choice?ac=1&amp;amp;from_search=true&amp;amp;qid=FWBh4M06P9&amp;amp;rank=3"&gt;The Choice&lt;/a&gt;, &lt;a href="https://www.goodreads.com/book/show/848514.Critical_Chain"&gt;Critical Chain&lt;/a&gt;), its Theory of Constraints (TOC) and his thinking tools. One of the thinking tools is called the Current Reality Tree (CRT). It is used when you are trying to find the root problem of a complex problem â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;I love Goldratt books (&lt;a href="https://www.goodreads.com/book/show/113934.The_Goal"&gt;The Goal&lt;/a&gt;, &lt;a href="https://www.goodreads.com/book/show/157385.It_s_Not_Luck?from_search=true&amp;amp;from_srp=true&amp;amp;qid=dQEjWkU3CN&amp;amp;rank=1"&gt;It's Not Luck&lt;/a&gt;, &lt;a href="https://www.goodreads.com/book/show/4845427-the-choice?ac=1&amp;amp;from_search=true&amp;amp;qid=FWBh4M06P9&amp;amp;rank=3"&gt;The Choice&lt;/a&gt;, &lt;a href="https://www.goodreads.com/book/show/848514.Critical_Chain"&gt;Critical Chain&lt;/a&gt;), its Theory of Constraints (TOC) and his thinking tools. One of the thinking tools is called the Current Reality Tree (CRT). It is used when you are trying to find the root problem of a complex problem. In this case, just out of curiosity, I have tried to write a CRT for the problem of cybersecurity: Why are big and important companies are having severe cybersecurity breaches? What can we do to improve this situation?&lt;/p&gt;
&lt;p&gt;I'm not going to explain how to design a CRT. I'm not even an expert and this probably has conceptual errors. I will fix it with time, while I improve how to write CRTs. In this post, I'm going to show mine and explain it. What you need to know is that an arrow from A to B means that A causes B. Another way of saying it, is to say that A is a necessary condition for B to happen. If we eliminate A, B will not happen.  If there is an ellipse on top of multiple arrows, it means that all the causes (A, A', A'') must be met for B to happen. Eliminating one, eliminates B. If there are multiple incoming arrows without an ellipse, that is an "or", so you would need to eliminate all the As to B not to happen.&lt;/p&gt;
&lt;p&gt;On the top of the tree we have the undesirable effects (UDEs). UDEs are what we see that is not working well and what we want to solve.&lt;/p&gt;
&lt;p&gt;The CRT does not state any solutions, only facts (causes of the UDEs, causes of the causes of the UDEs, etc.). The last causes, those on the bottom, without incoming arrows (except reinforcing loops), are the root causes. That means that if we solve the root causes, we will solve the problems derived from them.&lt;/p&gt;
&lt;p&gt;Goldratt's principle of Inherent Simplicity states that any complex problem, at the end, only have a few (probably one or two) root causes. If true, that is fantastic, because it means that the tree is not infinite or that it is not more complex when you grow it downwards, but the contrary, you make it more easy because at the bottom there will be less causes, not more.&lt;/p&gt;
&lt;p&gt;This is the CRT that I wrote for the cybersecurity problem:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Cybersecurity CRT" src="/images/cybersecurity_crt.jpg" width="780px"&gt;&lt;/p&gt;
&lt;h1&gt;Explanation of the CRT&lt;/h1&gt;
&lt;h2&gt;Companies continue having severe cybersecurity incidents&lt;/h2&gt;
&lt;p&gt;Our main and starting UDE is on the top: &lt;strong&gt;Companies continue having severe cybersecurity incidents&lt;/strong&gt;. That is a fact. But, what are the reasons? For me, the first direct reason, we may like it or not, is that &lt;strong&gt;Companies don't have enough cybersecurity controls&lt;/strong&gt;. If they had enough cybersecurity controls, independently of everything else, severe cybersecurity incidents won't happen.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Companies don't have enough cybersecurity controls&lt;/strong&gt; due to one or more of these reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Companies don't know how to secure their systems.&lt;/li&gt;
&lt;li&gt;Companies don't want to secure their systems.&lt;/li&gt;
&lt;li&gt;Companies don't know they need to secure their systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Companies don't know how to secure their systems&lt;/h2&gt;
&lt;p&gt;One of the causes of &lt;strong&gt;Companies continue having severe cybersecurity incidents&lt;/strong&gt; is that &lt;strong&gt;Companies don't know how to secure their systems&lt;/strong&gt;. They don't know what security controls would reduce the probability or the impact of a security threat to materialize in their company and cause severe damage. In the case of ransomware, that is the most pervasive and damaging security threat currently, this means that companies don't know which security controls they have to implement to avoid the ransomware to infect their systems, propagate, and ransom their data.&lt;/p&gt;
&lt;p&gt;I see two reasons why companies don't have this information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Companies don't have people who know how to secure their systems.&lt;/li&gt;
&lt;li&gt;Companies don't have people whose mission is to secure their systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's go down following the path of causes-effects that explain why "Companies don't have people who know how to secure their systems".&lt;/p&gt;
&lt;h2&gt;Companies don't have people who know how to secure their systems&lt;/h2&gt;
&lt;p&gt;Why people that are dedicated to security don't know which security measures can be implemented to reduce the risk of a security breach to acceptable levels? I know that in many cases these professional do know what to do, but the company don't let them do it. That is another branch under "Companies don't want to secure their systems", so we are not talking about this case here. Here I'm talking about not really knowing how to protect the organization against this.&lt;/p&gt;
&lt;p&gt;I have thought about two reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lack of cybersecurity people trained in technical security controls.&lt;/li&gt;
&lt;li&gt;People who has the mission of securing the organization systems are not cybersecurity professionals.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The second case happens when management has heard something about security, maybe in the news or maybe because they need to comply with some regulation related to security, and they assign one IT person, that is not a security professional, to be in charge of security. This happens usually because "Management and IT is not aware of the importance of having cybersecurity professionals in the team" and that happens, in general, because there is a "Lack of management cybersecurity awareness".&lt;/p&gt;
&lt;p&gt;Let's continue with the other branch.&lt;/p&gt;
&lt;h2&gt;Lack of cybersecurity people trained in technical security controls&lt;/h2&gt;
&lt;p&gt;Why there is a "Lack of cybersecurity people trained in technical security controls"? I think the reason is that these cybersecurity people are not trainned. But, why? I see two possible reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cybersecurity people think that they don't need to get training.&lt;/li&gt;
&lt;li&gt;Lack of good and cheap training material.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;"Cybersecurity people they don't need to get training" is being reinforced by the fact that "Lack of cybersecurity people trained in technical security controls". The less training, the less you think you need training. Dunning-Kruger effect in action. The CRT theory says that reinforcing loops like this are really powerful and we should focus on them when we want to find solutions.&lt;/p&gt;
&lt;p&gt;About the second, I'm not completely sure about that. Maybe the material is there but people don't know it or they don't do the effort of reading and studying it. In any case, the reason for these two cases, in my opinion, is the same. We have a "Cybersecurity community that rewards more the image than the knowledge". Some security rock stars that have been appearing in mass media have sent the message that security is cool and easy, without giving credit or raising awareness of the effort required to be a good security professional.&lt;/p&gt;
&lt;p&gt;Here we have finished. Let's return to the top of the tree, to the second big reason why Companies don't have enough security controls.&lt;/p&gt;
&lt;h2&gt;Companies don't want to secure their systems&lt;/h2&gt;
&lt;p&gt;Are there companies that don't want to secure their systems? Yes. And they have reasons. Ignoring or undervalue their reasons are not going to help. In this part of the tree I'm going to explore that.&lt;/p&gt;
&lt;p&gt;I see this possible reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Companies don't want to spend budget in cybersecurity.&lt;/li&gt;
&lt;li&gt;Companies do think it is ok to spend budget, but all the cybersecurity controls they know affect negatively on the business (e.g. to its agility).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's start with the second, which cause is clear for me and we have already talked about it: Companies don't have people that know how secure their systems. To think about security measures that are aligned with the business is difficult and it takes effort. They are not usually straighfoward. You have to take what books say and transform and adapt those recommendations. Cybersecurity professionals without the needed training tends to try to enforce security measures as they appear in the books, without taking the business into account.&lt;/p&gt;
&lt;p&gt;Well trained security professionals look for for the best solutions for the business which usually are non trivial solutions that do not affect negatively the business or whose negative impact is clearly worth it and makes sense.&lt;/p&gt;
&lt;h2&gt;Companies don't want to spend money on cybersecurity&lt;/h2&gt;
&lt;p&gt;Let's explore now why companies don't want to spend money on cybersecurity. Companies spend money in things they think they need. So, the reason is clear: the company (management) thinks that cybersecurity is not necessary so they choose to not spend money or time in cybersecurity. In my opinion, management thinks so because they are not aware of the security risks. They are usually very busy, and they need people around them that explains them what they need to know in a very easy straighforward way. Here we have a reinforcing cycle again...because companies don't have people whose mission is security, management don't have people around them that talk about security and explain it and make the risks visible.&lt;/p&gt;
&lt;p&gt;There is one more reason that explains why management are not aware of cybersecurity risks: in the cases that the company have cybersecurity people, sometimes, these cybersecurity people don't know how to talk about risks to management. Cybersecurity people is usually technical people. And we, technical people, do have in general a problem for explaining things in an easy understandable way. The reason for this is again lack of good cybersecurity training or lack of training aimed to talk about risks and how cyber risks affect companies.&lt;/p&gt;
&lt;h2&gt;Companies don't know how they need to protect their assets&lt;/h2&gt;
&lt;p&gt;This is the third reason why Companies don't have enough cybersecurity controls. The main reason for this, almost a synonim, is that management is not aware of the risks and we have already talked about the reasons.&lt;/p&gt;
&lt;h1&gt;Root causes and solutions&lt;/h1&gt;
&lt;p&gt;At the end, based on the logic explained, we have that the root causes of "Companies continue having severe cybersecurity incidents" are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Security community that rewards image over knowledge.&lt;/li&gt;
&lt;li&gt;Lack of management cybersecurity awareness.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's talk about solutions.&lt;/p&gt;
&lt;p&gt;For the second root cause, "Lack of management cybersecurity awareness", I think it is something that will improve with time. If cybersecurity is as important as we think it is, the number of security incidents will raise the awareness in a natural way. In my opinion, current security incidents due to ransomware, and its presence in mass media, are already raising these awareness levels. What we can do about this is talking more about them. To talk about them in a divulgative undertandable way that company managers can understand.&lt;/p&gt;
&lt;p&gt;About number one, it is in our hand to improve the situation. There are plenty of cons and opportunities to improve the security community. We have to raise awareness of the good security talks. We also have to participated, contribute, and create content. If we all contribute of improving the community, pushing it to the technical part, and raising awareness of the importance that cybersecurity professionals have the technical knowledge necessary to define good security measures that are aligned with the business and that are able to talk to management and make them aware of the importance of good cybersecurity for their business.&lt;/p&gt;
&lt;h1&gt;Improving the CRT&lt;/h1&gt;
&lt;p&gt;I'm pretty sure that the CRT has many errors, as I'm not an expert. I would like to receive your feedback about it in the form of comments here or maybe you can send me an email with your feedback to florencio.cano at gmail dot com.&lt;/p&gt;</content><category term="Security"></category><category term="toc"></category><category term="root-cause-analysis"></category></entry><entry><title>It's not about the number of vulnerabilities. It's about the risk.</title><link href="https://fcano.github.io/its-not-about-number-of-vulnerabilities-its-about-the-risk.html" rel="alternate"></link><published>2021-05-20T00:00:00+02:00</published><updated>2021-05-20T00:00:00+02:00</updated><author><name>Florencio Cano</name></author><id>tag:fcano.github.io,2021-05-20:/its-not-about-number-of-vulnerabilities-its-about-the-risk.html</id><summary type="html">&lt;p&gt;These are my thoughts about vulnerability management metrics after reading &lt;a href="https://medium.com/uber-security-privacy/business-friendly-vulnerability-management-metrics-cfd702fd7705"&gt;Business-friendly vulnerability management metrics&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The metrics described in the article above mainly measure the time that our assets have been vulnerable, taking into account the intensity (the number of vulnerabilities). The information of vulnerabilities is taken from vulnerability scanners.&lt;/p&gt;
&lt;p&gt;My â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;These are my thoughts about vulnerability management metrics after reading &lt;a href="https://medium.com/uber-security-privacy/business-friendly-vulnerability-management-metrics-cfd702fd7705"&gt;Business-friendly vulnerability management metrics&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The metrics described in the article above mainly measure the time that our assets have been vulnerable, taking into account the intensity (the number of vulnerabilities). The information of vulnerabilities is taken from vulnerability scanners.&lt;/p&gt;
&lt;p&gt;My opinion about how to measure the risk we face due to vulnerabilities is different.&lt;/p&gt;
&lt;p&gt;If I'm the person accountable for the risk of being affected by the exploitation of a vulnerability, what really matters to me is the real probability of a vulnerability being exploited, and the damage that can be done with it, and not the quantity of vulnerabilities or the time they are open. What I want to measure and control very well are the really dangerous vulnerabilities. So, I think we should focus on "quality" of the vulnerabilities, and not the number of them.&lt;/p&gt;
&lt;p&gt;When we measure people about the number of vulnerabilities, they tend to fix more vulnerabilities. But that is not what we want to reduce the risk in an effective way. We want that they fix the vulnerabilities which have more probability of being exploited and that can cause more damage to my organization. I prefer that they fix much less vulnerabilities, but more important.&lt;/p&gt;
&lt;p&gt;In order to determine how important is a vulnerability, we have to think about the probability of exploitation and the damage (impact) it would cause if it is successfully exploited. In order to do this, we have to take into account if the vulnerability is exploitable from the outside of the company or only from the inside. Also, if in order to exploit the vulnerability the attacker can be unathenticated or if some kind of account or permissions are needed. Also it is important to know if the vulnerability is easy to exploit (if it is trivial to exploit, if there exist exploits in the wild) or if it is difficult (for example vulnerabilities that can be exploited only in theory, only in a lab, only by advanced researchers). We have to think also if there are mitigating security controls that reduce the probability of being exploited or the damage in case they are exploited.&lt;/p&gt;
&lt;p&gt;For me, the most critical vulnerability would be a vulnerability that can be exploited from the outside, in a trivial way, and that would give direct access to a critical database (the importance of the asset is another factor that we have to take into account). I prefer to have 1000 internal vulnerabilities difficult to exploit the whole year than one of vulnerability that can be exploited by unathenticated users, from the outside, and that would give access to a credit card database during 1 hour.&lt;/p&gt;
&lt;p&gt;These are some metrics that are more interesting for me:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Time between an Important or Critical vulnerability is public and we know about it.&lt;/li&gt;
&lt;li&gt;Time between an Important or Critical vulnerability is public and we fix or mitigate it (mitigate = reduce to Moderate or Low by applying security controls).&lt;/li&gt;
&lt;li&gt;Time between we have an Important or Critical vulnerability (when not related to third parties, but only affects us, like an insecure configuration) and we know about it.&lt;/li&gt;
&lt;li&gt;Time between we have an Important or Critical vulnerability and we fix or mitigate it.&lt;/li&gt;
&lt;li&gt;Number of Important or Critical vulnerabilities in custom code/config that reach production.&lt;/li&gt;
&lt;li&gt;Number of times we classify a vulnerability as Moderate or Low, but then it is used by a Red Team or malicious actor to attack us or another organization (wrong analysis).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is true that by doing this analysis we can be wrong and a vulnerability that seems difficult to exploit is exploited and we get hacked. But, it is also true that we have to prioritize our work (time is limited), and we cannot aim to fix all vulnerabilities without prioritizing them.&lt;/p&gt;</content><category term="Security"></category><category term="metrics"></category><category term="risk"></category><category term="vulnerabilities"></category></entry></feed>